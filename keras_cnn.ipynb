{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as keras_backend\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, LeakyReLU, SpatialDropout2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\MDNE\\keras_cnn.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m    \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mget_device_properties(i)\u001b[39m.\u001b[39mname)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(torch.cuda.get_device_properties(i).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\MDNE\\keras_cnn.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m  \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNum GPUs Available: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as  tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivo de metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = 'spectogram/'\n",
    "spectograms = os.listdir(audio_path)\n",
    "\n",
    "#metadata with most_freq chords indicator\n",
    "df = pd.read_csv('metadata_final.csv', sep = ',')\n",
    "df_chords = df[df['most_freq'] == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"X-mel_spec.npy\")\n",
    "y = np.load(\"y-mel_spec.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_test_encoded = to_categorical(le.fit_transform(y_test))\n",
    "y_train_encoded = to_categorical(le.fit_transform(y_train))\n",
    "\n",
    "\n",
    "mapping = dict(zip(le.classes_, range(len(le.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755, 40, 608)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/21 14:30:24 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.tensorflow.autolog(every_n_iter = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How data should be structured\n",
    "num_rows = 608\n",
    "num_columns = 40 \n",
    "num_channels = 1\n",
    "\n",
    "# Reshape to fit the network input (channel last)\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "# Total number of labels to predict (equal to the network output nodes)\n",
    "num_labels = y_train_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    # Create a secquential object\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    # Conv 1\n",
    "    model.add(Conv2D(filters=32, \n",
    "                     kernel_size=(3, 3), \n",
    "                     input_shape=(num_rows, num_columns, num_channels)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=32, \n",
    "                     kernel_size=(3, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    # Max Pooling #1\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, \n",
    "                     kernel_size=(3, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, \n",
    "                     kernel_size=(3,3)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "   \n",
    "    # Reduces each h×w feature map to a single number by taking the average of all h,w values.\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "    # Softmax output\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 606, 38, 32)       320       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 606, 38, 32)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 606, 38, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 604, 36, 32)       9248      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 604, 36, 32)       0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 604, 36, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 302, 18, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 300, 16, 64)       18496     \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 300, 16, 64)       0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 300, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 298, 14, 64)       36928     \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 298, 14, 64)       0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 298, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 64)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66410 (259.41 KB)\n",
      "Trainable params: 66026 (257.91 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',  # duas classes\n",
    "    metrics=['accuracy'],  \n",
    "    optimizer='adam')\n",
    "\n",
    "# Display model architecture summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/21 14:36:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3f03783cb36b47a38c15da06eb491eb0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "189/189 [==============================] - 51s 272ms/step - loss: 0.3140 - accuracy: 0.1881 - val_loss: 0.3110 - val_accuracy: 0.1957\n",
      "Epoch 2/50\n",
      "189/189 [==============================] - 46s 240ms/step - loss: 0.3124 - accuracy: 0.1921 - val_loss: 0.3127 - val_accuracy: 0.1903\n",
      "Epoch 3/50\n",
      "189/189 [==============================] - 45s 239ms/step - loss: 0.3095 - accuracy: 0.2079 - val_loss: 0.3158 - val_accuracy: 0.1769\n",
      "Epoch 4/50\n",
      "189/189 [==============================] - 46s 242ms/step - loss: 0.3055 - accuracy: 0.2238 - val_loss: 0.3106 - val_accuracy: 0.2413\n",
      "Epoch 5/50\n",
      "189/189 [==============================] - 46s 242ms/step - loss: 0.3052 - accuracy: 0.2212 - val_loss: 0.3039 - val_accuracy: 0.2386\n",
      "Epoch 6/50\n",
      "189/189 [==============================] - 49s 261ms/step - loss: 0.3017 - accuracy: 0.2543 - val_loss: 0.3076 - val_accuracy: 0.1957\n",
      "Epoch 7/50\n",
      "189/189 [==============================] - 50s 264ms/step - loss: 0.2990 - accuracy: 0.2344 - val_loss: 0.3078 - val_accuracy: 0.2440\n",
      "Epoch 8/50\n",
      "189/189 [==============================] - 50s 266ms/step - loss: 0.2994 - accuracy: 0.2596 - val_loss: 0.3046 - val_accuracy: 0.2038\n",
      "Epoch 9/50\n",
      "189/189 [==============================] - 53s 283ms/step - loss: 0.2928 - accuracy: 0.2649 - val_loss: 0.3259 - val_accuracy: 0.2493\n",
      "Epoch 10/50\n",
      "189/189 [==============================] - 61s 325ms/step - loss: 0.2878 - accuracy: 0.2570 - val_loss: 0.2982 - val_accuracy: 0.2413\n",
      "Epoch 11/50\n",
      "189/189 [==============================] - 47s 246ms/step - loss: 0.2841 - accuracy: 0.3020 - val_loss: 0.3267 - val_accuracy: 0.1877\n",
      "Epoch 12/50\n",
      "189/189 [==============================] - 45s 239ms/step - loss: 0.2841 - accuracy: 0.3219 - val_loss: 0.2967 - val_accuracy: 0.2949\n",
      "Epoch 13/50\n",
      "189/189 [==============================] - 48s 254ms/step - loss: 0.2804 - accuracy: 0.3046 - val_loss: 0.3063 - val_accuracy: 0.2440\n",
      "Epoch 14/50\n",
      "189/189 [==============================] - 48s 256ms/step - loss: 0.2759 - accuracy: 0.3152 - val_loss: 0.3186 - val_accuracy: 0.2011\n",
      "Epoch 15/50\n",
      "189/189 [==============================] - 45s 237ms/step - loss: 0.2715 - accuracy: 0.3550 - val_loss: 0.3503 - val_accuracy: 0.2279\n",
      "Epoch 16/50\n",
      "189/189 [==============================] - 45s 238ms/step - loss: 0.2669 - accuracy: 0.3576 - val_loss: 0.3303 - val_accuracy: 0.2091\n",
      "Epoch 17/50\n",
      "189/189 [==============================] - 52s 275ms/step - loss: 0.2651 - accuracy: 0.3656 - val_loss: 0.2930 - val_accuracy: 0.3190\n",
      "Epoch 18/50\n",
      "189/189 [==============================] - 48s 253ms/step - loss: 0.2623 - accuracy: 0.3748 - val_loss: 0.3695 - val_accuracy: 0.2493\n",
      "Epoch 19/50\n",
      "189/189 [==============================] - 50s 265ms/step - loss: 0.2553 - accuracy: 0.3921 - val_loss: 0.4184 - val_accuracy: 0.2332\n",
      "Epoch 20/50\n",
      "189/189 [==============================] - 46s 244ms/step - loss: 0.2547 - accuracy: 0.3987 - val_loss: 0.3138 - val_accuracy: 0.2735\n",
      "Epoch 21/50\n",
      "189/189 [==============================] - 46s 245ms/step - loss: 0.2500 - accuracy: 0.4172 - val_loss: 0.3087 - val_accuracy: 0.2842\n",
      "Epoch 22/50\n",
      "189/189 [==============================] - 46s 244ms/step - loss: 0.2454 - accuracy: 0.4172 - val_loss: 0.3242 - val_accuracy: 0.2654\n",
      "Epoch 23/50\n",
      "189/189 [==============================] - 49s 259ms/step - loss: 0.2472 - accuracy: 0.4106 - val_loss: 0.3286 - val_accuracy: 0.3083\n",
      "Epoch 24/50\n",
      "189/189 [==============================] - 51s 270ms/step - loss: 0.2351 - accuracy: 0.4649 - val_loss: 0.3357 - val_accuracy: 0.2842\n",
      "Epoch 25/50\n",
      "189/189 [==============================] - 51s 271ms/step - loss: 0.2346 - accuracy: 0.4490 - val_loss: 0.2725 - val_accuracy: 0.3217\n",
      "Epoch 26/50\n",
      "189/189 [==============================] - 51s 268ms/step - loss: 0.2390 - accuracy: 0.4623 - val_loss: 0.3708 - val_accuracy: 0.2681\n",
      "Epoch 27/50\n",
      "189/189 [==============================] - 46s 241ms/step - loss: 0.2362 - accuracy: 0.4503 - val_loss: 0.3434 - val_accuracy: 0.3083\n",
      "Epoch 28/50\n",
      "189/189 [==============================] - 53s 283ms/step - loss: 0.2310 - accuracy: 0.4530 - val_loss: 0.3084 - val_accuracy: 0.3539\n",
      "Epoch 29/50\n",
      "189/189 [==============================] - 53s 281ms/step - loss: 0.2256 - accuracy: 0.4821 - val_loss: 0.2916 - val_accuracy: 0.3029\n",
      "Epoch 30/50\n",
      "189/189 [==============================] - 52s 275ms/step - loss: 0.2292 - accuracy: 0.4728 - val_loss: 0.3157 - val_accuracy: 0.3619\n",
      "Epoch 31/50\n",
      "189/189 [==============================] - 47s 247ms/step - loss: 0.2261 - accuracy: 0.4927 - val_loss: 0.2742 - val_accuracy: 0.3458\n",
      "Epoch 32/50\n",
      "189/189 [==============================] - 51s 272ms/step - loss: 0.2250 - accuracy: 0.4742 - val_loss: 0.2715 - val_accuracy: 0.3539\n",
      "Epoch 33/50\n",
      "189/189 [==============================] - 50s 266ms/step - loss: 0.2206 - accuracy: 0.4834 - val_loss: 0.4401 - val_accuracy: 0.2440\n",
      "Epoch 34/50\n",
      "189/189 [==============================] - 48s 256ms/step - loss: 0.2159 - accuracy: 0.5325 - val_loss: 0.2577 - val_accuracy: 0.3432\n",
      "Epoch 35/50\n",
      "189/189 [==============================] - 46s 246ms/step - loss: 0.2192 - accuracy: 0.5219 - val_loss: 0.3753 - val_accuracy: 0.3003\n",
      "Epoch 36/50\n",
      "189/189 [==============================] - 48s 256ms/step - loss: 0.2133 - accuracy: 0.5523 - val_loss: 0.3670 - val_accuracy: 0.2091\n",
      "Epoch 37/50\n",
      "189/189 [==============================] - 45s 238ms/step - loss: 0.2074 - accuracy: 0.5404 - val_loss: 0.4553 - val_accuracy: 0.2172\n",
      "Epoch 38/50\n",
      "189/189 [==============================] - 45s 237ms/step - loss: 0.2095 - accuracy: 0.5510 - val_loss: 0.2865 - val_accuracy: 0.3619\n",
      "Epoch 39/50\n",
      "189/189 [==============================] - 45s 239ms/step - loss: 0.2037 - accuracy: 0.5616 - val_loss: 0.3537 - val_accuracy: 0.3512\n",
      "Epoch 40/50\n",
      "189/189 [==============================] - 45s 238ms/step - loss: 0.2051 - accuracy: 0.5510 - val_loss: 0.2744 - val_accuracy: 0.4129\n",
      "Epoch 41/50\n",
      "189/189 [==============================] - 45s 238ms/step - loss: 0.2046 - accuracy: 0.5563 - val_loss: 0.3297 - val_accuracy: 0.3727\n",
      "Epoch 42/50\n",
      "189/189 [==============================] - 47s 249ms/step - loss: 0.1945 - accuracy: 0.5960 - val_loss: 0.3894 - val_accuracy: 0.3432\n",
      "Epoch 43/50\n",
      "189/189 [==============================] - 45s 241ms/step - loss: 0.1980 - accuracy: 0.5656 - val_loss: 0.3411 - val_accuracy: 0.3137\n",
      "Epoch 44/50\n",
      "189/189 [==============================] - 44s 234ms/step - loss: 0.1932 - accuracy: 0.6026 - val_loss: 0.3542 - val_accuracy: 0.2493\n",
      "Epoch 45/50\n",
      "189/189 [==============================] - 44s 233ms/step - loss: 0.1918 - accuracy: 0.5748 - val_loss: 0.3792 - val_accuracy: 0.2761\n",
      "Epoch 46/50\n",
      "189/189 [==============================] - 44s 233ms/step - loss: 0.1905 - accuracy: 0.5868 - val_loss: 0.3403 - val_accuracy: 0.3378\n",
      "Epoch 47/50\n",
      "189/189 [==============================] - 44s 233ms/step - loss: 0.1848 - accuracy: 0.6185 - val_loss: 0.3183 - val_accuracy: 0.3324\n",
      "Epoch 48/50\n",
      "189/189 [==============================] - 44s 234ms/step - loss: 0.1833 - accuracy: 0.6159 - val_loss: 0.4662 - val_accuracy: 0.3298\n",
      "Epoch 49/50\n",
      "189/189 [==============================] - 44s 233ms/step - loss: 0.1847 - accuracy: 0.6424 - val_loss: 0.3736 - val_accuracy: 0.3351\n",
      "Epoch 50/50\n",
      "189/189 [==============================] - 50s 267ms/step - loss: 0.1820 - accuracy: 0.6291 - val_loss: 0.3346 - val_accuracy: 0.3512\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\alves\\AppData\\Local\\Temp\\tmpwchs0yyz\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alves\\AppData\\Local\\Temp\\tmpwchs0yyz\\model\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train_encoded, \n",
    "                    batch_size=4, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_test,y_test_encoded),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 328ms/step\n",
      "F1-Score:  0.3002048912124947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      A#:maj       0.33      0.04      0.07        27\n",
      "      C#:maj       0.50      0.15      0.24        39\n",
      "       C:maj       0.33      0.03      0.05        37\n",
      "      D#:maj       0.30      0.78      0.43        27\n",
      "       D:maj       0.29      0.70      0.41        37\n",
      "       E:maj       0.52      0.62      0.57        37\n",
      "      F#:maj       0.31      0.70      0.43        33\n",
      "       F:maj       0.39      0.34      0.36        50\n",
      "      G#:maj       0.75      0.15      0.26        39\n",
      "       G:maj       0.30      0.15      0.20        47\n",
      "\n",
      "    accuracy                           0.35       373\n",
      "   macro avg       0.40      0.37      0.30       373\n",
      "weighted avg       0.41      0.35      0.30       373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds_score = model.predict(X_test)\n",
    "pred_idx = tf.math.argmax(preds_score, axis = 1)\n",
    "y_test_idx = tf.math.argmax(y_test_encoded, axis = 1)\n",
    "\n",
    "target_names = mapping.keys()\n",
    "\n",
    "print('F1-Score: ', f1_score(y_test_idx, pred_idx, average = 'macro'))\n",
    "\n",
    "print(classification_report(y_test_idx, pred_idx, target_names= target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(373,), dtype=int64, numpy=\n",
       "array([4, 1, 2, 1, 0, 7, 1, 3, 6, 4, 6, 4, 6, 7, 5, 8, 5, 8, 3, 8, 5, 0,\n",
       "       0, 7, 7, 1, 3, 3, 7, 2, 5, 7, 3, 2, 9, 5, 4, 4, 3, 4, 3, 9, 0, 6,\n",
       "       5, 8, 9, 1, 3, 4, 7, 8, 8, 1, 5, 4, 7, 1, 7, 7, 4, 9, 9, 0, 9, 7,\n",
       "       8, 9, 9, 3, 1, 1, 7, 9, 0, 7, 7, 1, 8, 2, 8, 9, 7, 5, 1, 0, 7, 5,\n",
       "       1, 1, 5, 4, 2, 8, 0, 7, 9, 5, 1, 6, 9, 5, 8, 9, 4, 8, 2, 6, 9, 0,\n",
       "       9, 2, 5, 4, 7, 7, 3, 6, 0, 9, 6, 5, 6, 3, 1, 5, 3, 1, 2, 4, 7, 5,\n",
       "       9, 2, 8, 2, 4, 6, 2, 6, 9, 4, 3, 1, 4, 9, 1, 4, 8, 9, 5, 6, 6, 7,\n",
       "       7, 1, 3, 7, 3, 8, 2, 7, 1, 6, 5, 9, 4, 2, 8, 6, 9, 2, 2, 6, 0, 5,\n",
       "       2, 8, 0, 8, 8, 0, 5, 0, 7, 4, 7, 5, 1, 9, 2, 9, 7, 8, 0, 4, 7, 3,\n",
       "       3, 7, 0, 9, 6, 2, 9, 3, 0, 9, 9, 6, 4, 1, 3, 2, 7, 4, 4, 9, 8, 6,\n",
       "       1, 7, 1, 5, 0, 1, 8, 2, 2, 6, 7, 1, 7, 7, 6, 1, 2, 4, 1, 7, 3, 1,\n",
       "       8, 4, 9, 4, 9, 7, 8, 5, 8, 4, 9, 2, 9, 2, 8, 7, 1, 4, 1, 4, 2, 1,\n",
       "       0, 0, 1, 8, 2, 2, 6, 6, 4, 9, 7, 4, 7, 5, 3, 4, 5, 7, 9, 5, 5, 9,\n",
       "       5, 3, 7, 3, 9, 6, 8, 2, 2, 7, 0, 4, 9, 8, 8, 8, 2, 6, 2, 8, 8, 0,\n",
       "       9, 9, 5, 6, 5, 1, 2, 0, 9, 7, 6, 5, 0, 1, 6, 7, 8, 1, 8, 6, 3, 3,\n",
       "       2, 4, 1, 1, 5, 0, 1, 8, 7, 3, 6, 7, 5, 2, 3, 6, 2, 6, 5, 5, 8, 4,\n",
       "       9, 0, 5, 6, 4, 0, 9, 7, 7, 5, 9, 7, 8, 4, 7, 9, 9, 8, 9, 2, 2],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "#print('Acurácia: ', f1_score(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
