{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as keras_backend\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, LeakyReLU, SpatialDropout2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in e:\\mdne\\.venv\\lib\\site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\MDNE\\keras_cnn.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m    \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mget_device_properties(i)\u001b[39m.\u001b[39mname)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(torch.cuda.get_device_properties(i).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\MDNE\\keras_cnn.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m  \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/MDNE/keras_cnn.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNum GPUs Available: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as  tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivo de metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = 'spectogram/'\n",
    "spectograms = os.listdir(audio_path)\n",
    "\n",
    "#metadata with most_freq chords indicator\n",
    "df = pd.read_csv('metadata_final.csv', sep = ',')\n",
    "df_chords = df[df['most_freq'] == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"X-mel_spec.npy\")\n",
    "y = np.load(\"y-mel_spec.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_test_encoded = to_categorical(le.fit_transform(y_test))\n",
    "y_train_encoded = to_categorical(le.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755, 40, 608)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How data should be structured\n",
    "num_rows = 608\n",
    "num_columns = 40 \n",
    "num_channels = 1\n",
    "\n",
    "# Reshape to fit the network input (channel last)\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "# Total number of labels to predict (equal to the network output nodes)\n",
    "num_labels = y_train_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    # Create a secquential object\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    # Conv 1\n",
    "    model.add(Conv2D(filters=32, \n",
    "                     kernel_size=(3, 3), \n",
    "                     input_shape=(num_rows, num_columns, num_channels)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=32, \n",
    "                     kernel_size=(3, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    # Max Pooling #1\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, \n",
    "                     kernel_size=(3, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, \n",
    "                     kernel_size=(3,3)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "   \n",
    "    # Reduces each h√ów feature map to a single number by taking the average of all h,w values.\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "    # Softmax output\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 606, 38, 32)       320       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 606, 38, 32)       0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 606, 38, 32)       128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 604, 36, 32)       9248      \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 604, 36, 32)       0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 604, 36, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 302, 18, 32)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 300, 16, 64)       18496     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 300, 16, 64)       0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 300, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 298, 14, 64)       36928     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 298, 14, 64)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 298, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 64)                0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66410 (259.41 KB)\n",
      "Trainable params: 66026 (257.91 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',  # duas classes\n",
    "    metrics=['accuracy'],  \n",
    "    optimizer='adam')\n",
    "\n",
    "# Display model architecture summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 [==============================] - 59s 305ms/step - loss: 0.5275 - accuracy: 0.1377 - val_loss: 0.5615 - val_accuracy: 0.0992\n",
      "Epoch 2/30\n",
      "189/189 [==============================] - 74s 390ms/step - loss: 0.3221 - accuracy: 0.1695 - val_loss: 0.4224 - val_accuracy: 0.1421\n",
      "Epoch 3/30\n",
      "189/189 [==============================] - 66s 350ms/step - loss: 0.3137 - accuracy: 0.1907 - val_loss: 0.3506 - val_accuracy: 0.1072\n",
      "Epoch 4/30\n",
      "189/189 [==============================] - 72s 383ms/step - loss: 0.3136 - accuracy: 0.1868 - val_loss: 0.3152 - val_accuracy: 0.1984\n",
      "Epoch 5/30\n",
      "189/189 [==============================] - 52s 273ms/step - loss: 0.3120 - accuracy: 0.2040 - val_loss: 0.3204 - val_accuracy: 0.1903\n",
      "Epoch 6/30\n",
      "189/189 [==============================] - 53s 280ms/step - loss: 0.3112 - accuracy: 0.1947 - val_loss: 0.3162 - val_accuracy: 0.1689\n",
      "Epoch 7/30\n",
      "189/189 [==============================] - 61s 323ms/step - loss: 0.3088 - accuracy: 0.2066 - val_loss: 0.3341 - val_accuracy: 0.1769\n",
      "Epoch 8/30\n",
      "189/189 [==============================] - 61s 322ms/step - loss: 0.3066 - accuracy: 0.2079 - val_loss: 0.3261 - val_accuracy: 0.1662\n",
      "Epoch 9/30\n",
      "189/189 [==============================] - 57s 299ms/step - loss: 0.3056 - accuracy: 0.2106 - val_loss: 0.3150 - val_accuracy: 0.1823\n",
      "Epoch 10/30\n",
      "189/189 [==============================] - 70s 372ms/step - loss: 0.3000 - accuracy: 0.2358 - val_loss: 0.3301 - val_accuracy: 0.1850\n",
      "Epoch 11/30\n",
      "189/189 [==============================] - 68s 358ms/step - loss: 0.2989 - accuracy: 0.2344 - val_loss: 0.3258 - val_accuracy: 0.1850\n",
      "Epoch 12/30\n",
      "189/189 [==============================] - 61s 321ms/step - loss: 0.2949 - accuracy: 0.2490 - val_loss: 0.3040 - val_accuracy: 0.2064\n",
      "Epoch 13/30\n",
      "189/189 [==============================] - 55s 293ms/step - loss: 0.2935 - accuracy: 0.2556 - val_loss: 0.3298 - val_accuracy: 0.2011\n",
      "Epoch 14/30\n",
      "189/189 [==============================] - 48s 253ms/step - loss: 0.2921 - accuracy: 0.2331 - val_loss: 0.2977 - val_accuracy: 0.2386\n",
      "Epoch 15/30\n",
      "189/189 [==============================] - 48s 254ms/step - loss: 0.2872 - accuracy: 0.2821 - val_loss: 0.2953 - val_accuracy: 0.2440\n",
      "Epoch 16/30\n",
      "189/189 [==============================] - 48s 255ms/step - loss: 0.2859 - accuracy: 0.2821 - val_loss: 0.3195 - val_accuracy: 0.1635\n",
      "Epoch 17/30\n",
      "189/189 [==============================] - 48s 254ms/step - loss: 0.2802 - accuracy: 0.2940 - val_loss: 0.3645 - val_accuracy: 0.1877\n",
      "Epoch 18/30\n",
      "189/189 [==============================] - 53s 281ms/step - loss: 0.2780 - accuracy: 0.3232 - val_loss: 0.3166 - val_accuracy: 0.1930\n",
      "Epoch 19/30\n",
      "189/189 [==============================] - 54s 285ms/step - loss: 0.2810 - accuracy: 0.2768 - val_loss: 0.2995 - val_accuracy: 0.2681\n",
      "Epoch 20/30\n",
      "189/189 [==============================] - 54s 283ms/step - loss: 0.2757 - accuracy: 0.3272 - val_loss: 0.2913 - val_accuracy: 0.2627\n",
      "Epoch 21/30\n",
      "189/189 [==============================] - 53s 283ms/step - loss: 0.2683 - accuracy: 0.3589 - val_loss: 0.2972 - val_accuracy: 0.2681\n",
      "Epoch 22/30\n",
      "189/189 [==============================] - 54s 286ms/step - loss: 0.2664 - accuracy: 0.3497 - val_loss: 0.3828 - val_accuracy: 0.2761\n",
      "Epoch 23/30\n",
      "189/189 [==============================] - 54s 286ms/step - loss: 0.2643 - accuracy: 0.3497 - val_loss: 0.2726 - val_accuracy: 0.3003\n",
      "Epoch 24/30\n",
      "189/189 [==============================] - 60s 318ms/step - loss: 0.2613 - accuracy: 0.3642 - val_loss: 0.3275 - val_accuracy: 0.3244\n",
      "Epoch 25/30\n",
      "189/189 [==============================] - 56s 295ms/step - loss: 0.2568 - accuracy: 0.3947 - val_loss: 0.2913 - val_accuracy: 0.3271\n",
      "Epoch 26/30\n",
      "189/189 [==============================] - 54s 286ms/step - loss: 0.2582 - accuracy: 0.3589 - val_loss: 0.2969 - val_accuracy: 0.3271\n",
      "Epoch 27/30\n",
      "189/189 [==============================] - 53s 283ms/step - loss: 0.2501 - accuracy: 0.3974 - val_loss: 0.2963 - val_accuracy: 0.3512\n",
      "Epoch 28/30\n",
      "189/189 [==============================] - 53s 282ms/step - loss: 0.2477 - accuracy: 0.3894 - val_loss: 0.2847 - val_accuracy: 0.3512\n",
      "Epoch 29/30\n",
      "189/189 [==============================] - 54s 286ms/step - loss: 0.2466 - accuracy: 0.4199 - val_loss: 0.2843 - val_accuracy: 0.3190\n",
      "Epoch 30/30\n",
      "189/189 [==============================] - 54s 286ms/step - loss: 0.2402 - accuracy: 0.4464 - val_loss: 0.3893 - val_accuracy: 0.2708\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train_encoded, \n",
    "                    batch_size=4, \n",
    "                    epochs=30, \n",
    "                    validation_data=(X_test,y_test_encoded),\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
